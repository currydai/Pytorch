{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型描述："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_1,x_2->y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y=10*x_1+2*x_2+1*x_1*x_2$$\n",
    "$$y=e^{-\\frac {t}{c}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 首先y是由x1，x2引起变化的\n",
    "* 目前情况是只知道不同时间t条件下的y值，反推x1,x2与y的关系"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 我们需要拟合$y=f(x1,x2)$,按照传统做法提取x1，x2特征，然后做拟合\n",
    "* 但是我们只知道y和t的关系，因此图和从y和t的关系中提出x1,x2相关特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1D CNN 可以很好地应用于传感器数据的时间序列分析（比如陀螺仪或加速度计数据）；同样也可以很好地用于分析具有固定长度周期的信号数据（比如音频信号）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 数据生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rand(a,b,length):\n",
    "    data=[]\n",
    "    for i in range(length):\n",
    "        data.append(random.uniform(a,b))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decay(sig1,sig2):\n",
    "    data=[]\n",
    "    for x1,x2 in zip(sig1,sig2):\n",
    "        y=2*x1*np.exp(-t/c)+2*x2*np.exp(-t/c)\n",
    "        data.append(y)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=1   #时间常数\n",
    "t=np.array([1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])  #观测时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=Rand(1,100,10000)\n",
    "x2=Rand(1,100,10000)\n",
    "y=decay(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1的大小为: (10000, 1)\n",
      "x2的大小为: (10000, 1)\n",
      "y的大小为: (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "x1=np.array(x1).reshape(-1,1)\n",
    "x2=np.array(x2).reshape(-1,1)\n",
    "print(\"x1的大小为:\",x1.shape)\n",
    "print(\"x2的大小为:\",x2.shape)\n",
    "print(\"y的大小为:\",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n=random.randint(1,1000)\n",
    "plt.plot(t,y[n,:])\n",
    "plt.legend(['zhouqi:%s'%n])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因此：我们观测值是不同周期下相同时刻段内的的$f(x)$分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据生成数据可以发现：\n",
    "* 如果不同时刻之间没有关系的话，那么可以按照时间分为20个模型分别取预测\n",
    "* 如果不同时刻之间有关系的话，那么就不能单独20个模型去预测，要统一去预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 用PyTorch实现CNN用来刻画模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1, 1, 20])\n"
     ]
    }
   ],
   "source": [
    "y.reshape(-1,20,1)\n",
    "y_tensor=torch.from_numpy(y).reshape(-1,1,1,20)\n",
    "print(y_tensor.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.1365e+02, 4.1809e+01, 1.5381e+01, 5.6583e+00, 2.0816e+00,\n",
       "          7.6577e-01, 2.8171e-01, 1.0364e-01, 3.8125e-02, 1.4025e-02,\n",
       "          5.1597e-03, 1.8981e-03, 6.9829e-04, 2.5689e-04, 9.4503e-05,\n",
       "          3.4766e-05, 1.2790e-05, 4.7050e-06, 1.7309e-06, 6.3676e-07]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tensor[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "x=np.hstack((x1,x2))\n",
    "x1_tensor=torch.from_numpy(x1)\n",
    "x2_tensor=torch.from_numpy(x2)\n",
    "x_tensor=torch.from_numpy(x).reshape(-1,1,2,1)\n",
    "print(x1_tensor.size())\n",
    "print(x2_tensor.size())\n",
    "print(x_tensor.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TEM_net(nn.Module): \n",
    "    def __init__(self):\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        #定义卷积层\n",
    "        self.conv_unit=nn.Sequential(\n",
    "        nn.Conv1d(1,5,kernel_size=5,stride=1,padding=0),\n",
    "        nn.AvgPool1d(kernel_size=2,stride=2,padding=0),\n",
    "        \n",
    "        nn.Conv1d(5,5,kernel_size=3,stride=1,padding=0),\n",
    "        nn.AvgPool1d(kernel_size=2,stride=2,padding=0)\n",
    "        )\n",
    "        \n",
    "        #定义全连接层\n",
    "        self.fc_unit=nn.Sequential(\n",
    "        nn.Linear(3*1*5,128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128,64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,2)\n",
    "        )\n",
    "        \n",
    "    #数据从此进来，经过定义好的各层网络，最终输出\n",
    "    def forward(self,x):\n",
    "        #batchsz=x.size(0)\n",
    "        print(x.size())\n",
    "        #卷积层\n",
    "        x=self.conv_unit(x) \n",
    "        \n",
    "        # 对数据维度作处理，以适应全连接层\n",
    "        x=x.view(x.size(0),-1)\n",
    "        logits=self.fc_unit(x)\n",
    "        \n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=TEM_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteon = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-278-b0f0e41b28f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mlogist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0moss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriteon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 计算损失\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m               \u001b[1;31m# 旧梯度清零\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                     \u001b[1;31m# 误差反向传播\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    960\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    961\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[1;32m--> 962\u001b[1;33m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[0;32m    963\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2466\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2467\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2468\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[0;32m   2262\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[0;32m   2263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2266\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "batches=500\n",
    "for epoch in range(100):\n",
    "    for i in range(10000):\n",
    "        x=y_tensor[i].to(torch.float32)\n",
    "        logist = model(x) \n",
    "        oss = criteon(logist, x_tensor[i]) # 计算损失\n",
    "        optimizer.zero_grad()               # 旧梯度清零\n",
    "        loss.backward()                     # 误差反向传播\n",
    "        optimizer.step()                    # 梯度更新\n",
    "    print(epoch, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
